{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where I am experimenting with how to call and download the data from datahub's Covid-19 database\n",
    "\n",
    "The location of the data site is https://datahub.io/core/covid-19#data\n",
    "The files are in both JSON and CSV file format\n",
    "\n",
    "US data is located at /core/covid-19/r/us_confirmed.cvs (or .json)\n",
    "US data is located at /core/covid-19/r/us_deaths.cvs (or .json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 # BeautifulSoup an HTML parser\n",
    "import csv # library for manipulating csv files (pandas will be better since that's what is used on datahub.io)\n",
    "import os # library for saving the files within my systm\n",
    "import re # regular expression library for finding data within the data\n",
    "import requests # Downloads data from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the file name that I save to my machine from the website so I'm not puling requests all the time\n",
    "file_name = \"covid-19-data.html\" \n",
    "# website of the data\n",
    "base_url = \"https://datahub.io/core/covid-19#data\" \n",
    "#Can try to make an OOP to incorperate these two variables into it for doing the rest of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code to search the datahub website to find and download the latest data.\n",
    "## This can of course be addressed manually but for practice this code would \n",
    "## help me search for the link to download the data\n",
    "\n",
    "## This can of course be addressed manually but for practice this code would \n",
    "## help me search for the link to download the data\n",
    "\n",
    "if os.path.isfile(file_name): # may wish to delete this after the code has run or compare dates\n",
    "    print(f\"Using locally cached data from {file_name}\") \n",
    "    with open(file_name, encoding='utf-8') as file:\n",
    "        html_text = file.read()\n",
    "else:\n",
    "    print(f\"Loading data from {base_url}\")\n",
    "    req = requests.get(base_url)\n",
    "    req.raise_for_status()\n",
    "    html_text = req.text\n",
    "    with open(file_name, \"w\", encoding='utf-8') as file:\n",
    "        file.write(html_text)\n",
    "res = bs4.BeautifulSoup(html_text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = list(res.select('.download > a'))# selects \"a href\" tags underneath .downlads with the CSS selectors\n",
    "links #This does take specific knowlege on how this particular website is setup and not code to be used generally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay now I have the locations of the files... now what?  \n",
    "# Website seems to start with https://datahub.io then /core/covid-19...\n",
    "File_links= list(re.findall(r'\"([^\"]*)\"', str(links)))\n",
    "File_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next is do I set something that lets one choose what to download?  .csv? .json? .zip?\n",
    "while True:\n",
    "    File_Type= input ('What File Type do you wish to download? (.csv, .json, .zip)' )\n",
    "    if '.csv' in File_Type or '.json' in File_Type or '.zip' in File_Type:\n",
    "        File_links= set(re.findall(r'\"([^\"]*)'+File_Type, str(links)))\n",
    "        print ('File type accepted')\n",
    "        break\n",
    "    else:\n",
    "        print (\"Wrong File Type!\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Type in File_links:\n",
    "    if File_Type in Type:\n",
    "        print ('http://datahub.io'+Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method tries to select for css codes which start with a href and end with .csv \n",
    "# It's a more general approach to finding the file locations\n",
    "if File_Type =='.csv':\n",
    "    links_href=res.select(\"a[href$='.csv']\")\n",
    "elif Type =='.json':\n",
    "    links_href=res.select(\"a[href$='.json']\")\n",
    "else:\n",
    "    links_href=res.select(\"a[href$='.zip']\")\n",
    "links_href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a set (to remove duplicates) of the text within the \" \"\n",
    "Files_href = set (re.findall(r'\"([^\"]*)\"', str(links_href))) \n",
    "Files_href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#That grabs some things which are not .csv\n",
    "#this alteration will get the addresses of all the files\n",
    "Files_csv = set (re.findall(r'\"/core/covid-19/r/([^\"]*)\"', str(links_href))) \n",
    "Files_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for address in Files_csv:\n",
    "    File_path = 'https://datahub.io/core/covid-19/r/'+address\n",
    "    print (File_path)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This bit of code works to download the file to my computer to use.\n",
    "for address in Files_csv:\n",
    "    File_path = 'https://datahub.io/core/covid-19/r/'+ address\n",
    "    response = requests.get(File_path)# downloads the csv file\n",
    "    with open(os.path.join(address), 'wb') as f: # creates a file to write to\n",
    "        f.write(response.content) #writes the data to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I should probably do something like the webpage downloader to make sure I only download if I need new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next step is to start combing through the data to start making some sense of it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
